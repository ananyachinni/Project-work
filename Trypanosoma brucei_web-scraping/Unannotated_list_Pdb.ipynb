{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aace715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\ananya\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ananya\\anaconda3\\lib\\site-packages (from BeautifulSoup4) (2.3.1)\n",
      "Code is 3O6O\n",
      "urlpage =  https://www.rcsb.org/structure/3O6O\n",
      "Code is 3OMU\n",
      "urlpage =  https://www.rcsb.org/structure/3OMU\n",
      "Code is 6HIV\n",
      "urlpage =  https://www.rcsb.org/structure/6HIV\n",
      "Code is 6HIX\n",
      "urlpage =  https://www.rcsb.org/structure/6HIX\n",
      "Code is 6YXX\n",
      "urlpage =  https://www.rcsb.org/structure/6YXX\n",
      "Code is 6YXY\n",
      "urlpage =  https://www.rcsb.org/structure/6YXY\n",
      "Code is 4BI9\n",
      "urlpage =  https://www.rcsb.org/structure/4BI9\n",
      "Code is 4BIA\n",
      "urlpage =  https://www.rcsb.org/structure/4BIA\n",
      "Code is 4BP8\n",
      "urlpage =  https://www.rcsb.org/structure/4BP8\n",
      "Code is 4BP9\n",
      "urlpage =  https://www.rcsb.org/structure/4BP9\n",
      "Code is 1OEP\n",
      "urlpage =  https://www.rcsb.org/structure/1OEP\n",
      "Code is 2PU1\n",
      "urlpage =  https://www.rcsb.org/structure/2PU1\n",
      "Code is 2MEK\n",
      "urlpage =  https://www.rcsb.org/structure/2MEK\n",
      "Code is 6LP1\n",
      "urlpage =  https://www.rcsb.org/structure/6LP1\n",
      "Code is 7AOI\n",
      "urlpage =  https://www.rcsb.org/structure/7AOI\n",
      "Code is 4V8M\n",
      "urlpage =  https://www.rcsb.org/structure/4V8M\n",
      "Code is 3K7U\n",
      "urlpage =  https://www.rcsb.org/structure/3K7U\n",
      "Code is 3K80\n",
      "urlpage =  https://www.rcsb.org/structure/3K80\n",
      "Code is 3K81\n",
      "urlpage =  https://www.rcsb.org/structure/3K81\n",
      "Code is 3STB\n",
      "urlpage =  https://www.rcsb.org/structure/3STB\n",
      "Code is 4DNI\n",
      "urlpage =  https://www.rcsb.org/structure/4DNI\n",
      "Code is 6SG9\n",
      "urlpage =  https://www.rcsb.org/structure/6SG9\n",
      "Code is 6SGB\n",
      "urlpage =  https://www.rcsb.org/structure/6SGB\n",
      "Code is 6HIW\n",
      "urlpage =  https://www.rcsb.org/structure/6HIW\n",
      "Code is 6HIZ\n",
      "urlpage =  https://www.rcsb.org/structure/6HIZ\n",
      "Code is 7PUA\n",
      "urlpage =  https://www.rcsb.org/structure/7PUA\n",
      "Code is 6T4R\n",
      "urlpage =  https://www.rcsb.org/structure/6T4R\n",
      "Code is 6T68\n",
      "urlpage =  https://www.rcsb.org/structure/6T68\n",
      "Code is 2WOI\n",
      "urlpage =  https://www.rcsb.org/structure/2WOI\n",
      "Code is 2WOV\n",
      "urlpage =  https://www.rcsb.org/structure/2WOV\n",
      "Code is 2WOW\n",
      "urlpage =  https://www.rcsb.org/structure/2WOW\n",
      "Code is 2WP5\n",
      "urlpage =  https://www.rcsb.org/structure/2WP5\n",
      "Code is 2WP6\n",
      "urlpage =  https://www.rcsb.org/structure/2WP6\n",
      "Code is 2WPC\n",
      "urlpage =  https://www.rcsb.org/structure/2WPC\n",
      "Code is 2WPE\n",
      "urlpage =  https://www.rcsb.org/structure/2WPE\n",
      "Code is 2WPF\n",
      "urlpage =  https://www.rcsb.org/structure/2WPF\n",
      "Code is 4NEV\n",
      "urlpage =  https://www.rcsb.org/structure/4NEV\n",
      "Code is 6BTL\n",
      "urlpage =  https://www.rcsb.org/structure/6BTL\n",
      "Code is 6BU7\n",
      "urlpage =  https://www.rcsb.org/structure/6BU7\n",
      "Code is 6OEX\n",
      "urlpage =  https://www.rcsb.org/structure/6OEX\n",
      "Code is 6OEY\n",
      "urlpage =  https://www.rcsb.org/structure/6OEY\n",
      "Code is 6OEZ\n",
      "urlpage =  https://www.rcsb.org/structure/6OEZ\n",
      "Code is 6RB5\n",
      "urlpage =  https://www.rcsb.org/structure/6RB5\n",
      "Code is 7NVP\n",
      "urlpage =  https://www.rcsb.org/structure/7NVP\n",
      "Code is 6H4G\n",
      "urlpage =  https://www.rcsb.org/structure/6H4G\n",
      "Code is 4EU1\n",
      "urlpage =  https://www.rcsb.org/structure/4EU1\n",
      "Code is 4W5K\n",
      "urlpage =  https://www.rcsb.org/structure/4W5K\n",
      "Code is 6XZ6\n",
      "urlpage =  https://www.rcsb.org/structure/6XZ6\n",
      "Code is 3HIY\n",
      "urlpage =  https://www.rcsb.org/structure/3HIY\n",
      "Code is 3HJ1\n",
      "urlpage =  https://www.rcsb.org/structure/3HJ1\n",
      "Code is 3HJ4\n",
      "urlpage =  https://www.rcsb.org/structure/3HJ4\n",
      "Code is 4DK2\n",
      "urlpage =  https://www.rcsb.org/structure/4DK2\n",
      "Code is 4DK4\n",
      "urlpage =  https://www.rcsb.org/structure/4DK4\n",
      "Code is 4DKB\n",
      "urlpage =  https://www.rcsb.org/structure/4DKB\n",
      "Code is 4DL8\n",
      "urlpage =  https://www.rcsb.org/structure/4DL8\n",
      "Code is 4DLC\n",
      "urlpage =  https://www.rcsb.org/structure/4DLC\n"
     ]
    }
   ],
   "source": [
    "!pip install BeautifulSoup4\n",
    "#\n",
    "# import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import csv\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "#-----------------------------------------------------------------------------    \n",
    "def process(urlpage):\n",
    "# Output line\n",
    "    line=[]\n",
    "    line2=[]\n",
    "# query the website and return the html to the variable 'page'\n",
    "    page = urllib.request.urlopen(urlpage)\n",
    "# parse the html using beautiful soup and store in variable 'soup'\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "\n",
    "#\n",
    "#    pubmedDOI\n",
    "# https://stackoverflow.com/questions/59333559/how-to-implement-if-statement-with-beautifulsoup-and-selenium - for below if loop\n",
    "    literature = soup.find_all('li', id='pubmedDOI')\n",
    "    if literature:\n",
    "        #    Find doi after 4'th > and first < after that \n",
    "        doi=get_item(str(literature[0]),4,0)\n",
    "#         print(\"doi\",doi)\n",
    "    else:\n",
    "        doi = \"\"\n",
    "    \n",
    "#\n",
    "#    pubmedLinks\n",
    "# https://stackoverflow.com/questions/59333559/how-to-implement-if-statement-with-beautifulsoup-and-selenium - for below if loop\n",
    "    pubmedlinks = soup.find_all('li', id='pubmedLinks')\n",
    "    if pubmedlinks:\n",
    "        #    Find doi after 4'th > and first < after that \n",
    "        pubmedno=get_item(str(pubmedlinks[0]),4,0)\n",
    "#         print(\"pubmed ID\", pubmedno)\n",
    "    else:\n",
    "        pubmedno = \"\"\n",
    "    \n",
    "\n",
    "\n",
    "#\n",
    "#    Classification\n",
    "#\n",
    "    classification = soup.find_all('li', id='header_classification')\n",
    " #  After 3rd \">\" and the \"<\" after that \n",
    "    classif=get_item(str(classification[0]),3,0)\n",
    "#     print(\"Classification\", classif)\n",
    "\n",
    "    \n",
    "\n",
    "#    Organism\n",
    "#\n",
    "#\n",
    "    organism = soup.find_all('li', id='header_organism')\n",
    "    \n",
    "    searchorganism=str(organism[0]) # this is what we willserach of organisms.\n",
    "    organisms_list=\"\"   # Empty list for results\n",
    "#   There can be more than one organism, which starts after 'rcsb_entity_source_organism.taxonomy_lineage.name:\n",
    "#   and ends after the first \"\">\n",
    "    organism_tag='rcsb_entity_source_organism.taxonomy_lineage.name:'\n",
    "#    Here we find how many organisms there are and where they start in the strimg (in to list \"starts\")\n",
    "    searchlen=len(organism_tag) # Lenth of search tag that we have to jump over to find organism\n",
    " #  Find start (a list) position in string of serach tag  \n",
    "    starts =[i for i in range(len(searchorganism)) if searchorganism.startswith\n",
    "             (organism_tag, i)]\n",
    "#   Here we loop over the starting positions and find the \">\" in each, put in \"ends\" where end[0] is the first\n",
    "    for j in range(len(starts)):\n",
    "        ends =[i for i in range(len(searchorganism[starts[j]+searchlen:len(searchorganism)]))if searchorganism[starts[j]+searchlen:len(searchorganism)].startswith(\">\", i)]\n",
    "#          Write out from start position at of search tag to the ends[0] after that, minus 1, to avoid the\" \n",
    "        organisms_list=organisms_list+ \" \" + searchorganism[starts[j]+searchlen:starts[j]+searchlen+ends[0]-1]\n",
    "#         print(organisms_list)\n",
    "\n",
    "  \n",
    "    \n",
    "#\n",
    "#    Method\n",
    "#\n",
    "    ExpMethod = soup.find_all('li', id='exp_header_0_method')\n",
    "\n",
    "    expMethod=get_item(str(ExpMethod[0]),3,0)\n",
    "#     print(\"Experimental Method\",expMethod)\n",
    "    line.append([code,doi, pubmedno,classif,expMethod,organisms_list])\n",
    "    return line\n",
    "\n",
    "    \n",
    "def get_item(string,no_greater,no_less):\n",
    "#-----------------------------------------------------------------------------\n",
    "# Parse out item between no_greater \">\" and no_less \"<\" after that.\n",
    "#  Split on \">\" up to no_greater \n",
    "#    print(\"string\", string)\n",
    "    found_item=string.split(\">\", no_greater)\n",
    "    return found_item[no_greater].split(\"<\")[no_less]\n",
    "\n",
    "def get_li_item(soup,id_str,no_greater,no_less):\n",
    "#-----------------------------------------------------------------------------\n",
    "#\n",
    "#   li item. With ide=id_stream. Parse itemb etween no_greater \">\"'s and no_less \"<\"'s after that.\n",
    "#\n",
    "# <li id=\"header_organism\"><strong>Organism(s):&nbsp</strong><a href=\"/search?q=rcsb_entity_source_organism.taxonomy_lineage.name:Sus scrofa\">Sus scrofa</a></li>\n",
    "#\n",
    "    li_str = soup.find_all('li', id=id_str)\n",
    " #  Split on \">\" up to third occurrence \n",
    "    li_item=str(li_str[0]).split(\">\", no_greater)[no_greater]\n",
    "#   Split before first occurence of \"<\"  \n",
    "#    print(\"OrganismsAnswer\",li_item.split(\"<\")[no_less])\n",
    "    li_item=li_item.split(\"<\")[no_less]\n",
    "    return li_item\n",
    "\n",
    "def get_fromtable_column(soup,id_str,skip,column,no_greater,no_less,code):\n",
    "#\n",
    "#   Get table column from table with id=id_str. Skip ths number of rows\n",
    "#   Table rom Column in teh rows\n",
    "#   Parse item between no_greater \">\"'s and no_less \"<\"'s after that. \n",
    "    table1 = soup.find('table', id=id_str)\n",
    "#    print(\"Table1\",table1)\n",
    "# Ugly - has two ligandsmaintable. One for oligos and one ro small molecuels.Only one - easier to just make\n",
    "# and exception since it was the only one out of 95. The \"Oligosacharides\" and \"Small Molecules\" are both \n",
    "# in <div> tags. Better to find these and then sift ligandstable within.\n",
    "    if (table1 and code!=\"3b08\"):   \n",
    "        tr1 = table1.findAll(['tr'])\n",
    "        listitems=\"\"\n",
    "        for item in tr1[skip:]:\n",
    "            table_column = item.findAll('td')[column].contents\n",
    "            singleitem=str(table_column).split(\">\", no_greater)[no_greater]\n",
    "            singleitem=singleitem.split(\"<\",1)[no_less]\n",
    "            listitems=listitems+\" \"+singleitem\n",
    "\n",
    "    else:\n",
    "        listitems=\"None\"\n",
    "    return listitems\n",
    "#\n",
    "def get_fromtable_column_row(soup,id_str,skip,column,row,no_greater,no_less):\n",
    "#\n",
    "#   Get table column from table with id=id_str. Skip ths number of rows\n",
    "#   Table from Column in the rows\n",
    "#   Parse item between no_greater \">\"'s and no_less \"<\"'s after that. \n",
    "    table1 = soup.find('table', id=id_str)\n",
    "    tr1 = table1.findAll(['tr'])\n",
    "    singleitem=\"\"\n",
    "    table_column = tr1[row].findAll('td')[column].contents\n",
    "\n",
    "    singleitem=str(table_column)\n",
    "    return singleitem\n",
    "\n",
    "\n",
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result += str(element)\n",
    "    return result\n",
    "\n",
    "\n",
    "#\n",
    "# Main \n",
    "#\n",
    "# Take  a list of pdb code. Loop over 'https://www.rcsb.org/structure/'+str(code) to find data\n",
    "\n",
    "\n",
    "csvline=[]  #This is what will be written out\n",
    "\n",
    "# Read in list of codes\n",
    "\n",
    "\n",
    "with open('C:/unannotated_pdb_list.csv') as csvfile:   # Open csv file\n",
    "#with open('complement.csv') as csvfile:   # Open csv file\n",
    "    readCSV = csv.reader(csvfile, delimiter=',') # Read csv file using a comma a delimiter\n",
    "    for code in readCSV: # Loop over rows in csv file\n",
    "\n",
    "\n",
    "        code = \"\".join(code)  # Takes out brackets and quotes to give clean pdbcode string\n",
    "        print(\"Code is\",code)\n",
    "        urlpage ='https://www.rcsb.org/structure/'+str(code)\n",
    "        print (\"urlpage = \", urlpage)\n",
    "\n",
    "#         numb=process(urlpage)   # Get data from page. Set rows and columns in process function\n",
    "        csvline=csvline+process(urlpage)  \n",
    "#         print(\"Process \",numb)\n",
    "csvfile.close()\n",
    "\n",
    "# print(\"line\",csvline)\n",
    "\n",
    "# Write to csv file.\n",
    "with open('C:/unannotated_pdb_info.csv', 'w') as csvFile:\n",
    "#with open('testop.csv', 'w') as csvFile:\n",
    "# https://stackoverflow.com/questions/19663413/python-beautifulsoup-empty-rows-in-csv-file - for removing empty lines from writing in the file\n",
    "    writer = csv.writer(csvFile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL, lineterminator = \"\\n\")\n",
    "    writer.writerow(['Code','doi','Pubmed ID', 'Classification','ExpMethod','Organism(s)'])\n",
    "\n",
    "    for i in csvline:\n",
    "        writer.writerow(i)\n",
    "csvFile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d9199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
